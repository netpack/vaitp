"how to group elements effectively in a huge list by their first character in blank i am following the answer of the following stackoverflow question to accomplish my task as follows. blank list group by first character..import json.from itertools import groupby..#load data.with open('input.txt', 'r') as f:.    concepts = [].    for concept in f:.        concepts.append(concept.strip())..print(len(concepts))..concepts_list = [list(g) for k, g in groupby(concepts, key=lambda x: x[0])]..concepts_dict = {}.for item in concepts_list:.    concepts_dict[item[0][0]] = item..with open(""concepts_preprocessed_dictionary.txt"", ""w"") as fw:.    fw.write(json.dumps(concepts_dict))...however, i am wondering why this code is not working when there are huge number of concepts in the list (aproximately 13,000,000 concepts). surprisingly the program executes in seconds and when i check the dictionary it contains wrong results (in other words the dictionary file is only 1kb in size and contain mostly one or two elements per grouped lists)...unfortunately, i am not in a position to share my concept list as it violates some privacy issues. ..but i found a long word list in the following github page: https://raw.githubusercontent.com/dwyl/english-words/master/words.txt..however, unlike the above mentioned dataset my current dataset is only Ã lphabetically ordered by first character` (i.e. as follows)..my dataset: only first letter is m, but the remaining words are not albetically ordered...methods    .machine learning    .mic...dataset i have mentioned: nicely ordered based on characters...machine learning.methods.mic...please let me know if there is any further details needed."
