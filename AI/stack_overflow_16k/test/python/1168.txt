"make a progress counter in concurrent blank from multiprocessing import process, pool.from bs4 import beautifulsoup..alreadyprocessedfile = 0.0.processlength = 0.0..def convertedfile(filepath):..    filename = os.path.basename(filepath).split('.')[0]..    print(""total: ""+str(processlength)+"", current: ""+str(alreadyprocessedfile).          + "", percentage: ""+ str((alreadyprocessedfile+1.0)/(processlength+1)))..    #business logic..    print(""one file is saved at the location: ""+r'e:xxxsecprojectprocessedsec10kfiles2012qtr1/'+filename+'-finaldoc.txt')..def getfilepath(path):.    return glob.glob(os.path.join(path, '*.txt'))..if __name__ == '__main__':.    s = r""e:xxxsecprojectsec10kfiles2012qtr1"".    filelist = getfilepath(s).    processlength = len(filelist).    p = pool(40).    p.map(convertedfile, filelist)...this is basically a shortened version of the blank program. i don't have a wrapper class outside and i want to have a counter inside to keep track of the progress (so i know when the program will stop). however the program (def covertedfile() have a problem accessing the changed variables: alreadyprocessedfile and processlength)..i know concurrency might have problems with shared state, but how can you accomplish a counter without some degree of shared state?? and why can't the concurrent function access the variable outside of it?....also as weird as it may sound, this concurrent version program can't process all files (about 5000 of them) under one directory. i wonder if the program is shut down while some processes are still running. is this a possibility?"
