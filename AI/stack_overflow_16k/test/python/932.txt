"finding and deleting duplicate lines in a file(the fastest and most efficient way) as the title says, i want to find and delete duplicate lines in a file. that is pretty easy to do...the catch is that i want to know what is the fastest and most efficient way to do that (let's say that you have gigabytes worth of files and you want to do this as efficient and as fast as you can)..if you know some method...as complicated as it is that can do that i would like to know. i heard some stuff like loop unrolling and started to second guess that the most simple things are the fastest so i am curious."
