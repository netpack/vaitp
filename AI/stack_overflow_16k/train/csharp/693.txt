"dividing by 2 vs multiplying by 0.5 consider the following:..void foo(int start, int end).{.    int mid = (start + end) / 2;.}..void bar(int start, int end).{.    int mid = (start + end) * 0.5;.}...why does foo compiles successfully while bar does not? dividing by 2 implicitly casts the result to an int while multiplying by 0.5 gives an un-casted double:...  cannot implicitly convert type 'double to int. an explicit conversion.  exists(are you missing a cast?)...what was the blank language designers' reasoning behind this?"
