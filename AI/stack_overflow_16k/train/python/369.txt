"boto3, read gzip from s3 and print content i'm trying to read a gzip file from s3 - the ""native"" format f the file is a csv. ultimately, after uncompressing the file, i'd like to be able to ""see"" the content so i can read the number of lines in the csv and keep count of it...my ""basic"" attempts are here - still just trying to print the contents of the file. this attempt just tells me that there is no such file or directory.....i know i'm also probably erroneously thinking the unzipped csv file will be in json format - but that's the next ""issue"" once i get to read the unzipped contents.....[errno 2] no such file or directory: 'smsusagereports/eu-west-1/2018/01/02/001.csv.gz' ....import gzip.import boto3.import json.s3 = boto3.resource('s3').s3_client = boto3.client('s3').bucket = s3.bucket('snssmsreports').for obj in bucket.objects.filter(prefix='smsusagereports/eu-west-1/2018/01/02'):.    json_object = s3_client.get_object(bucket=bucket.name, key=obj.key).    file_name = obj.key.    obj = bucket.object(file_name).    file_body = obj.get()[""body""].read()..    # gzip stuff here.    f=gzip.open(file_name,'rb').    file_content=f.read().    #print file_content..    #jsonfilereader = json_object['body'].read().    jsondict = json.loads(file_content).    #table = dynamodb.table('sns').    #table.put_item(item=jsondict).    print('{0}:{1}'.format(bucket.name, obj.key)).    print(jsondict)...ok, so i updated my code as follow:..import zipfile.import gzip.import boto3.import io.import json..import pandas as pd...s3 = boto3.resource('s3').s3_client = boto3.client('s3').bucket = s3.bucket('snssmsreports').for obj in bucket.objects.filter(prefix='smsusagereports/eu-west-1/2018/01/02'):.    json_object = s3_client.get_object(bucket=bucket.name, key=obj.key).    file_name = obj.key.    obj = bucket.object(file_name)..    s3_client.download_file(bucket.name, file_name, '../../tmp/file.gz')..    gzip_name = '../../tmp/file.gz'.    # gzip stuff here.    with gzip.open(gzip_name,'rb') as f:.        file_content=f.read().    str_file = str(file_content)..    csvfile = open('../../tmp/testfile.csv','w') .    csvfile.write(str_file) .    csvfile.close()  ..    #table = dynamodb.table('sns').    #table.put_item(item=jsondict)..    #pandas csv reader.    df1 = pd.read_csv('../../tmp/testfile.csv').    print(df1)..    #print('{0}:{1}'.format(bucket.name, obj.key)).    #print(file_content)..    #table = dynamodb.table('sns').    #table.put_item(item=jsondict)...this does not throw any errors anymore, but the output only has one row and 135 columns, so panda is not liking the actual content of the csv, or my conversion to str() is not the right way to do it?"
