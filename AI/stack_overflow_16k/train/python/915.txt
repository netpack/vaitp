"optimizing a counter that loops through documents to check how many words from the document appear in a list i am using a lexicon of positive and negative words, and i want to count how many positive and negative words appear in each document from a large corpus. the corpus has almost 2 million documents, so the code i'm running is taking too long to count all these occurrences...i have tried using numpy, but get a memory error when trying to convert the list of documents into an array...this is the code i am currently running to count just the positive words in each document...reviews_pos_wc = []..for review in reviews_upper:.    pos_words = 0.    for word in review:.        if word in pos_word_list:.            pos_words += 1.    reviews_pos_wc.append(pos_words)...after running this for half an hour, it only gets through 300k documents...i have done a search for similar questions on this website. i found someone else doing a similar thing, but not nearly on the same scale as they only used one document. the answer suggested using the counter class, but i thought this would just add more overhead."
