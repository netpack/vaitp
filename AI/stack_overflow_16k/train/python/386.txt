"program not working as expected i'm trying to run an example program for a web crawler from netinstructions.com but it is not working. i run the program using:..spider(""http://www.netinstructions.com/"", ""blank"", 50)...but it always returns..1 visiting: http://www.netinstructions.com.word never found...no matter what url i enter. the code for the program is below:..from html.parser import htmlparser  .from urllib.request import urlopen  .from urllib import parse..# we are going to create a class called linkparser that inherits some.# methods from htmlparser which is why it is passed into the definition.class linkparser(htmlparser):..    # this is a function that htmlparser normally has.    # but we are adding some functionality to it.    def handle_starttag(self, tag, attrs):.        # we are looking for the begining of a link. links normally look.        # like &lt;a href=""www.someurl.com""&gt;&lt;/a&gt;.        if tag == 'a':.            for (key, value) in attrs:.                if key == 'href':.                    # we are grabbing the new url. we are also adding the.                    # base url to it. for example:.                    # www.netinstructions.com is the base and.                    # somepage.html is the new url (a relative url).                    #.                    # we combine a relative url with the base url to create.                    # an absolute url like:.                    # www.netinstructions.com/somepage.html.                    newurl = parse.urljoin(self.baseurl, value).                    # and add it to our colection of links:.                    self.links = self.links + [newurl]..    # this is a new function that we are creating to get links.    # that our spider() function will call.    def getlinks(self, url):.        self.links = [].        # remember the base url which will be important when creating.        # absolute urls.        self.baseurl = url.        # use the urlopen function from the standard blank 3 library.        response = urlopen(url).        # make sure that we are looking at html and not other things that.        # are floating around on the internet (such as.        # javascript files, css, or .pdfs for example).        if response.getheader('content-type')=='text/html':.            htmlbytes = response.read().            # note that feed() handles strings well, but not bytes.            # (a change from blank 2.x to blank 3.x).            htmlstring = htmlbytes.decode(""utf-8"").            self.feed(htmlstring).            return htmlstring, self.links.        else:.            return """",[]..# and finally here is our spider. it takes in an url, a word to find,.# and the number of pages to search through before giving up.def spider(url, word, maxpages):  .    pagestovisit = [url].    numbervisited = 0.    foundword = false.    # the main loop. create a linkparser and get all the links on the page..    # also search the page for the word or string.    # in our getlinks function we return the web page.    # (this is useful for searching for the word).    # and we return a set of links from that web page.    # (this is useful for where to go next).    while numbervisited &lt; maxpages and pagestovisit != [] and not foundword:.        numbervisited = numbervisited +1.        # start from the beginning of our collection of pages to visit:.        url = pagestovisit[0].        pagestovisit = pagestovisit[1:].        try:.            print(numbervisited, ""visiting:"", url).            parser = linkparser().            data, links = parser.getlinks(url).            if data.find(word)&gt; -1:.                foundword = true.                # add the pages that we visited to the end of our collection.                # of pages to visit:.                pagestovisit = pagestovisit + links.                print("" **success!**"").        except:.            print("" **failed!**"").    if foundword:.        print(""the word"", word, ""was found at"", url).    else:.        print(""word never found"")...does anyone know what's going on? i'm using blank 3.5 (32-bit) and running on windows 10."
