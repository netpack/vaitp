"blank searching through a txt file for urls i'm writing lots of urls into a txt file like this inside my script with a loop:..fwrite = open('visited.txt', 'a').fwrite.write('n{0}'.format(url)).fwrite.close()...then when i re-run later i don't want to process visited links so i do this:(visit is a list of new/old urls)..for x in visit:.    if x in open('visited.txt').read().lstrip('rn'):.        visit.remove(x).    else:.        continue...but this always skips half of the lines. if there are 1000 urls, it removes only 500 of it. tried both lstrip/rtsrip with n and rn but couldn't manage it"
