"parallel and asynchronous results i want to ssh into n hosts to check the output of a command. a successful run will return in ~2 seconds while timeouts may take 40 seconds each. as we can see for 5 hosts, best case is 10 seconds while worst case is more than 3 minutes...so i want to transparently execute them in parallel and when the last one has finished, i want to examine the outputs (and errors if they happened). and i dont want individual results to slow down the whole process.....heres the function i need to run in parallel:..def fetch_results_from_ssh( host):.    try:.        a = login_and_fetch_values().        return a.    except:.        throw exception(""something"")...heres the kind of wrapping i want to make above function asynchronous:..result_futures = [].for i in [""h1"",""h2"",""h3""].    result_futures.append( async( fetch_results_from_ssh( i))..for i in result_futures:.    if i.worked_fine():.        print ""host "" + host + ""value: "" + i.value #yes, i did not define host anywhere.    else:.        print ""host "" + host + ""error: "" + i.error.....how do i execute it in parallel? i prefer something doable with standard library, even if i need to code more."
