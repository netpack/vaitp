"def _table_query(request, fileid, conn=None, query=None, lazy=False, **kwargs):    """    Query a table specified by fileid    Returns a dictionary with query result if successful, error information    otherwise    @param request:     http request; querystring must contain key 'query'                        with query to be executed, or '*' to retrieve all rows.                        If query is in the format word-number, e.g. "Well-7",                        if will be run as (word==number), e.g. "(Well==7)".                        This is supported to allow more readable query strings.    @param fileid:      Numeric identifier of file containing the table    @param query:       The table query. If None, use request.GET.get('query')                        E.g. '*' to return all rows.                        If in the form 'colname-1', query will be (colname==1)    @param lazy:        If True, instead of returning a 'rows' list,                        'lazy_rows' will be a generator.                        Each gen.next() will return a list of row data                        AND 'table' returned MUST be closed.    @param conn:        L{omero.gateway.BlitzGateway}    @param **kwargs:    offset, limit    @return:            A dictionary with key 'error' with an error message                        or with key 'data' containing a dictionary with keys                        'columns' (an array of column names) and 'rows'                        (an array of rows, each an array of values)    """    if query is None:        query = request.GET.get("query")    if not query:        return dict(error="Must specify query parameter, use * to retrieve all")    col_names = request.GET.getlist("col_names")    ctx = conn.createServiceOptsDict()    ctx.setOmeroGroup("-1")    r = conn.getSharedResources()    t = r.openTable(omero.model.OriginalFileI(fileid), ctx)    if not t:        return dict(error="Table %s not found" % fileid)    try:        cols = t.getHeaders()        col_indices = range(len(cols))        if col_names:            enumerated_columns = (                [(i, j) for (i, j) in enumerate(cols) if j.name in col_names]                if col_names                else [(i, j) for (i, j) in enumerate(cols)]            )            cols = []            col_indices = []            for col_name in col_names:                for (i, j) in enumerated_columns:                    if col_name == j.name:                        col_indices.append(i)                        cols.append(j)                        break        rows = t.getNumberOfRows()        offset = kwargs.get("offset", 0)        limit = kwargs.get("limit", None)        if not offset:            offset = int(request.GET.get("offset", 0))        if not limit:            limit = (                int(request.GET.get("limit"))                if request.GET.get("limit") is not None                else rows            )        range_start = offset        range_size = limit        range_end = min(rows, range_start + range_size)        if query == "*":            hits = range(range_start, range_end)            totalCount = rows        else:            match = re.match(r"^(\w+)-(\d+)", query)            if match:                query = "(%s==%s)" % (match.group(1), match.group(2))            try:                logger.info(query)                hits = t.getWhereList(query, None, 0, rows, 1)                totalCount = len(hits)                # paginate the hits                hits = hits[range_start:range_end]            except Exception:                return dict(error="Error executing query: %s" % query)        def row_generator(table, h):            # hits are all consecutive rows - can load them in batches            idx = 0            batch = 1000            while idx < len(h):                batch = min(batch, len(h) - idx)                res = table.slice(col_indices, h[idx : idx + batch])                idx += batch                # yield a list of rows                yield [                    [col.values[row] for col in res.columns]                    for row in range(0, len(res.rowNumbers))                ]        row_gen = row_generator(t, hits)        rsp_data = {            "data": {                "column_types": [col.__class__.__name__ for col in cols],                "columns": [col.name for col in cols],            },            "meta": {                "rowCount": rows,                "totalCount": totalCount,                "limit": limit,                "offset": offset,            },        }        if not lazy:            row_data = []            # Use the generator to add all rows in batches            for rows in list(row_gen):                row_data.extend(rows)            rsp_data["data"]["rows"] = row_data        else:            rsp_data["data"]["lazy_rows"] = row_gen            rsp_data["table"] = t        return rsp_data    finally:        if not lazy:            t.close()"